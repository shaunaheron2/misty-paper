---
title: "Responsive Robots"
subtitle: "Preliminary Analysis of Trust and Performance Data"
author: "Shauna Heron"
date: today
format: 
    typst:
        fontsize: 10pt
warning: false
message: false
echo: false
---
 
Need plots showing pre and post trust with NFC (high, low, moderate) and then facet w/robot experience and language and also compare with the other post trust scale and individual trust items (human, robot, ai)

```{r}

library(tidyverse)
library(janitor)
library(scales)
library(corrplot)
library(sjPlot)
library(ggstatsplot)
library(psych)
library(performance)
library(Hmisc)
library(haven)
library(gtsummary)

session_df <- readRDS("full_session_data.rds")
survey_df <- readRDS("survey_data.rds") |>
  arrange(post_date)


set_gtsummary_theme(theme_gtsummary_journal("jama"))
set_gtsummary_theme(theme_gtsummary_compact())

df_flat_scores_final <- readRDS("full_dataset_with_items.rds") |>
  mutate(
    poor_comms = if_else(
      session_id %in% c('P46', 'P47', 'P50', 'P30', 'P32', 'P17', 'P14'),
      1,
      0
    )
  ) |>
  filter(poor_comms != 1)

df_long_scores_final <- readRDS("full_dataset_long_trust_post.csv") |>
  mutate(
    poor_comms = if_else(
      session_id %in% c('P46', 'P47', 'P50', 'P30', 'P32', 'P17', 'P14'),
      1,
      0
    )
  ) |>
  filter(poor_comms != 1)
```

::: callout-warning
These are preliminary results and analyses. Please do not distribute or cite without permission of the authors.
:::

# Results

## Participant characteristics and baseline measures

Participants in the control and responsive conditions were comparable with respect to demographic characteristics, academic background, prior experience with robots, and baseline attitudes toward robots (Table 1). In particular, baseline Negative Attitudes Towards Robots (NARS) and Need for Cognition scores were similar across groups, indicating that post-interaction differences were unlikely to reflect pre-existing attitudes.

```{r}
#| tbl-cap: "Participant Demographics and Baseline Characteristics by Group"

df_flat_scores_final |>
  mutate(age = as_factor(age)) |>
  data.frame() |>
  select(-post_date) |>
  droplevels() |>
  select(
    group,
    gender,
    age,
    program,
    robot_xp,
    native_english,
    nars_pre,
    #nars_social_influence_robots,
    #nars_emotion_robots,
    #nars_interaction_robots,
    nfc_pre
    #robot_trust_pre,
    #ai_trust_pre,
    #human_trust_pre
    #contains('trust')
    #-mytrust_pre
  ) |>
  tbl_summary(
    by = group,
    type = list(
      nars_pre ~ 'continuous',
      # nars_social_influence_robots ~ 'continuous',
      # nars_emotion_robots ~ 'continuous',
      # nars_interaction_robots ~ 'continuous',
      #human_trust_pre ~ 'continuous',
      #robot_trust_pre ~ 'continuous',

      #ai_trust_pre ~ 'continuous',
      nfc_pre ~ 'continuous'
    ),
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} / {N} ({p}%)"
    ),
    label = list(
      gender ~ "Gender",
      age ~ "Age Group",
      program ~ "Program",
      robot_xp ~ "Experience w/Robots",
      native_english ~ 'Native English Speaker',
      nfc_pre ~ 'Need for Cognition',
      nars_pre ~ "NARS Overall"
      # nars_social_influence_robots ~ "NARS: Social Influence",
      #nars_emotion_robots ~ "NARS: Emotions",
      # nars_interaction_robots ~ "NARS: Interaction"
    ),
    missing_text = ('Missing')
  ) |>
  add_n() |>
  add_p() |>
  #add_overall() |>
  bold_p() |>
  bold_labels() |>
  modify_caption(
    "Table 1. Participant Demographics and Baseline Characteristics by Group"
  )


```

##  Correlation Matrix of Key Variables

```{r}
#| fig-height: 7
#| fig-width: 7

df_flat <- df_flat_scores_final |>
  select(
    contains('pre'),
    contains('post'),
    -human_trust_pre,
    -robot_trust_pre,
    -ai_trust_pre,
    total_correct,
    n_turns,
    duration_mins,
    avg_response_ms,
    n_silence,
    n_engaged,
    n_frust,
    n_neg,
    prop_correct,
    suspect_correct,
    building_correct,
    zone_correct,
    floor_correct
  ) |>
  select(-contains('i_would'))


res2 <- rcorr(as.matrix(df_flat %>% select(where(is.numeric))))

corr <- cor(
  df_flat %>% select(where(is.numeric)),
  use = "pairwise.complete.obs"
)

testRes = cor.mtest(corr, conf.level = 0.95)
#c#orrplot(corr, p.mat = testRes$p,  cl.pos = 'n')

corrplot(
  corr,
  p.mat = testRes$p,
  insig = 'label_sig',
  sig.level = c(0.001, 0.01, 0.05),
  pch.cex = 0.9,
  pch.col = 'grey20'
)

# https://sjdm.org/dmidi/Need_for_Cognition_short.html
# Lins de Holanda Coelho G, H P Hanel P, J Wolf L. The Very Efficient Assessment of Need for
#Cognition: Developing a Six-Item Version. Assessment. 2020 Dec;27(8):1870-1885. doi:
#10.1177/1073191118793208. Epub 2018 Aug 10. PMID: 30095000; PMCID: PMC7545655
# https://rins.st.ryukoku.ac.jp/~nomura/docs/NARS_AAAI06.pdf
# items. hus, the minimum and maximum scores are 6 and
#  https://uhra.herts.ac.uk/id/eprint/13608/1/SyrdalDDautenhahn.pdf <-- discusses problems using standardized scale cross-culturally
```

## Post-interaction descriptive statistics

```{r}
#| tbl-cap: "Post-Interaction Outcome Measures by Group"
post_table <- df_flat_scores_final |>
  #drop_na(gender) |>
  select(group, contains('post'), contains('correct'), 63:76) |>
  data.frame() |>
  mutate(across(
    contains('post_trust'),
    ~ scales::rescale(.x, to = c(0, 100), min_old = 1, max_old = 5)
  )) |>
  select(-post_date)

post_table |>
  tbl_summary(
    by = group,
    type = list(
      post_trust_reliability ~ 'continuous',
      post_trust_feelings ~ 'continuous',
      post_trust_perception ~ 'continuous',
      total_correct ~ 'continuous',
      avg_response_ms ~ 'continuous',
      prop_correct ~ 'continuous',
      n_engaged ~ 'continuous',
      n_frust ~ 'continuous',
      n_neg ~ 'continuous'
    ),
    # missing=FALSE,
    statistic = list(
      all_continuous() ~ "{mean} ({sd})",
      all_categorical() ~ "{n} / {N} ({p}%)"
    ),
    label = list(
      suspect_correct ~ "Suspect ID Accuracy",
      status_correct ~ "Status ID Accuracy",
      duration_mins ~ "Avg Task Duration (mins)",

      total_correct ~ "Total Task Accuracy",
      n_turns ~ "Number of Dialogue Turns",
      n_silence ~ "Number of Silent Periods",
      avg_response_ms ~ "Avg Response Time (ms)",
      prop_correct ~ "Overall Task Accuracy",
      n_engaged ~ "Number of Engaged Responses",
      n_frust ~ "Number of Frustrated Responses",
      trust_perc_post ~ "Post-Task Trust Perception"
    )
  ) |>
  add_n() |>
  add_p() |>
  # add_overall() |>
  bold_p() |>
  #bold_labels() |>
  modify_caption("Table 2. Post-Interaction Raw Outcome Measures by Group")
```


## Need for Cognition and NARS Correlation Matrix

As expected, we find that higher Need for Cognition (NFC) scores are negatively correlated with Negative Attitudes Towards Robots (NARS) scores, indicating that individuals who enjoy effortful thinking tend to have more positive attitudes towards robots. This relationship is consistent with prior literature suggesting that cognitive engagement is associated with openness to new technologies. In terms of NARS subscales, NFC was negatively correlated with all three subscales, but was only Social Influence of Robots, Emotions in Interaction with Robots, and Situations of Interaction with Robots but correlation was weakest Social Influence of Robots and strongest with Interaction with Robots. In the literature, .............................. This suggests that individuals with higher NFC are less likely to hold negative attitudes across various dimensions of robot interaction.


```{r}
#| fig-height: 7
#| fig-width: 7

df_pre_cor <- df_flat_scores_final |>
  # drop_na(gender) |>
  select(
    session_id,
    group,
    age,
    program,
    robot_xp,
    native_english,
    contains('nars'),
    contains('pre')
  )

res2 <- rcorr(as.matrix(df_pre_cor %>% select(where(is.numeric))))

group_correlations <- df_pre_cor |>
  group_by(native_english) |>
  dplyr::summarize(cor = cor(nars_pre, nfc_pre))

df_pre_cor |>
  group_by(native_english) |>
  summarise(
    n = n(),
    mean_nfc = mean(nfc_pre, na.rm = TRUE),
    mean_nars = mean(nars_pre, na.rm = TRUE),
    mean_nars_interation = mean(nars_interaction_robots, na.rm = TRUE),
    mean_nars_emotion = mean(nars_emotion_robots, na.rm = TRUE),
    mean_nars_social = mean(nars_social_influence_robots, na.rm = TRUE)
  )

ggbetweenstats(x = native_english, y = nfc_pre, df_pre_cor)

df_pre_cor |>
  group_by(program) |>
  summarise(
    n = n(),
    mean_nfc = mean(nfc_pre, na.rm = TRUE),
    mean_nars = mean(nars_pre, na.rm = TRUE),
    mean_nars_interaction = mean(nars_interaction_robots, na.rm = TRUE),
    mean_nars_emotion = mean(nars_emotion_robots, na.rm = TRUE),
    mean_nars_social = mean(nars_social_influence_robots, na.rm = TRUE)
  )


df_pre_cor |>
  group_by(robot_xp) |>
  summarise(
    n = n(),
    mean_nfc = mean(nfc_pre, na.rm = TRUE),
    mean_nars = mean(nars_pre, na.rm = TRUE),
    mean_nars_interation = mean(nars_interaction_robots, na.rm = TRUE),
    mean_nars_emotion = mean(nars_emotion_robots, na.rm = TRUE),
    mean_nars_social = mean(nars_social_influence_robots, na.rm = TRUE)
  )

ggbetweenstats(x = robot_xp, y = nfc_pre, df_pre_cor)
ggbetweenstats(x = robot_xp, y = nars_pre, df_pre_cor)

grouped_ggbetweenstats(
  x = group,
  y = nfc_pre,
  df_pre_cor,
  grouping.var = robot_xp
)
grouped_ggbetweenstats(
  x = group,
  y = nars_pre,
  df_pre_cor,
  grouping.var = robot_xp
)

corr <- cor(
  df_pre_cor %>% select(where(is.numeric)),
  use = "pairwise.complete.obs"
)

testRes = cor.mtest(corr, conf.level = 0.95)
#corrplot(corr, p.mat = testRes$p,  cl.pos = 'n')

# corrplot(
#   corr,
#   p.mat = testRes$p,
#   insig = 'label_sig',
#   sig.level = c(0.001, 0.01, 0.05),
#   pch.cex = 0.9,
#   pch.col = 'grey20'
# )

# library("PerformanceAnalytics")
# chart.Correlation(
#   df_pre_cor |> select(where(is.numeric)),
#   histogram = TRUE,
#   pch = 19
# )

hist(df_pre_cor$nfc_pre)
hist(df_pre_cor$nars_pre)

ggplot(, aes(x = nfc_pre, fill = group)) +
  geom_density(alpha = 0.5)

ggplot(df_pre_cor, aes(x = nfc_pre, fill = group)) +
  geom_histogram(color = 'grey30', fill = "white") +
  facet_wrap(~group)
#https://uc-r.github.io/histograms
ggplot(df_pre_cor, aes(x = nars_pre, fill = group)) +
  geom_histogram(color = 'grey30', fill = "white") +
  facet_wrap(~group)
#corrplot(corr, p.mat = testRes$p, insig = 'p-value')
# ++++++++++++++++++++++++++++
# flattenCorrMatrix
# ++++++++++++++++++++++++++++
# cormat : matrix of the correlation coefficients
# pmat : matrix of the correlation p-values
flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor = (cormat)[ut],
    p = pmat[ut]
  )
}

flatmatrix <- flattenCorrMatrix(res2$r, res2$P)


# https://sjdm.org/dmidi/Need_for_Cognition_short.html
# Lins de Holanda Coelho G, H P Hanel P, J Wolf L. The Very Efficient Assessment of Need for
#Cognition: Developing a Six-Item Version. Assessment. 2020 Dec;27(8):1870-1885. doi:
#10.1177/1073191118793208. Epub 2018 Aug 10. PMID: 30095000; PMCID: PMC7545655
# https://rins.st.ryukoku.ac.jp/~nomura/docs/NARS_AAAI06.pdf
# items. hus, the minimum and maximum scores are 6 and
#  https://uhra.herts.ac.uk/id/eprint/13608/1/SyrdalDDautenhahn.pdf <-- discusses problems using standardized scale cross-culturally
```

## Descriptive Post-Test Results

Descriptive comparisons of post-interaction measures indicated that participants in the responsive condition reported consistently higher trust across all trust measures, with differences ranging from approximately 8 to 16 points on the 0–100 scale, although uncertainty remained high given the small sample. Notably, the responsive condition did not differ from control in objective task accuracy, suggesting that increased trust was not driven by improved task success. Instead, responsive interactions were characterized by longer durations, slower response times, and a higher number of AI-detected engaged responses, indicating a shift in interaction dynamics rather than performance.

```{r}

```

## Correlations

Several behavioral and task-level measures were correlated with post-interaction trust, consistent with the interpretation that trust judgments were shaped by interaction quality; these variables were not included as covariates in primary models to avoid conditioning on potential mediators.

Baseline negative attitudes toward robots were most strongly associated with affective components of trust rather than perceptions of reliability, suggesting that pre-existing attitudes primarily shape emotional responses to interaction rather than judgments of system competence. Conversely, objective task performance was selectively associated with perceived reliability, indicating that participants distinguished between affective and functional aspects of trust.

Future work with larger samples could formally test mediation pathways linking robot responsiveness, interaction fluency, affective responses, and trust judgments, as well as moderation by baseline attitudes toward robots and need for cognition.

Participants in the responsive condition also exhibited higher levels of AI-detected engagement during interaction, as indexed by a greater number of responses classified as positive affect (t-test result). This suggests that responsive behaviors altered the affective tone of the interaction itself.


## Post-test robot trust ratings

On the overall post-interaction trust score, the responsive-Misty group reports higher trust than the control group (M ≈ 73 vs M ≈ 63). 

Bayesian hierarchical models indicated higher post-interaction trust scores in the responsive robot condition across both trust-related scales (posterior mean differences ≈ 7–8 points on a 0–100 scale). Although 95% credible intervals overlapped zero, the posterior probability that the responsive condition increased trust was high for both measures (≈0.95), suggesting a robust directional effect alongside substantial individual variability.Sensitivity analyses using substantially wider priors yielded nearly identical posterior estimates for the group effect, indicating that results were not driven by prior specification.

In addition to directional effects, the posterior probability that the responsive condition increased trust by at least five points was approximately 0.70, suggesting a moderate likelihood of a practically meaningful effect despite substantial individual variability.

Descriptive comparisons of participant-level post-test scores indicated an approximately 10-point difference between conditions, although this did not reach conventional significance under a two-sample t-test, reflecting limited power (n = 29). Hierarchical Bayesian models that accounted for item-level structure yielded slightly smaller but consistent estimates (≈7–8 points) with high posterior probability of a positive effect. Notably, treating item-level responses as independent observations (i.e., ignoring nesting) substantially inflated apparent precision, underscoring that the observed uncertainty is primarily a function of sample size rather than absence of an effect. A larger sample would allow more precise estimation of the effect magnitude.

Although the two post-test trust instruments differed in original response format, both were linearly rescaled to a 0–100 metric for interpretability and comparability. Analyses were conducted separately for each scale, and posterior predictive checks indicated that Gaussian hierarchical models adequately captured the central tendency and variability of scores despite discretization. Negative attitudes toward robots (NARS) were negatively correlated with post-interaction trust, consistent with prior literature, and likely contributed to between-participant variability in post-only estimates.


```{r}

ggbetweenstats(
  x = group,
  y = post_trust,
  data = df_flat_scores_final
)

ggbetweenstats(
  x = group,
  y = trust_perc_post,
  data = df_flat_scores_final
)
```



## Task accuracy 

For task *performance* (accuracy on the mystery task items), the biggest predictor isn’t group, it’s language: native English speakers have much higher odds of determing the correct answer (OR ≈ 8.2, 95% CI ~2–34). The treatment (responsive vs control) goes in the expected direction (OR < 1 for control) but isn’t statistically significant in this small sample. This suggests that speech recognition / accent issues and general language comprehension are strongly constraining task success, and may be masking any performance advantage of the responsive robot. On the other hand, both robots were using the same ASR and dialogue system with access to the same information, so we shouldn't necessarily see an effect here.

## Interpretation so far

Trust: despite the small sample, we already see a pretty robust treatment effect on perceived trust in the robot that holds up in the multilevel models after controlling for attitudes and language background.

Performance: accuracy is dominated by language / accent effects, which we hadn’t explicitly designed for. This may be a useful finding in itself for HRI and ASR-based systems, but it complicates clean inferences about responsiveness → task performance. Though we do see a trend in a positive direction.

My read is that these data are very encouraging as a pilot! We have evidence that the responsive, pro-active behaviour of the responsive manipulation was doing something psychologically meaningful (higher trust), even with only 21 participants and an imbalanced design (where it should be difficult to detect small effects!). We’ve also uncovered an important design issue: language background and STT quality are non-trivial confounds for both trust and performance, especially in an international / CS student population.

## In terms of what to do now:

If we can recruit a few more participants without too much pain, I'd love to top up the control group and try to get a better balance of native vs non-native speakers in each condition. This may not be possible in this current study iteration but maybe could expand to a larger thesis?? :) Even getting to something like ~12–15 per group would help the trust analyses and give us a bit more power on accuracy (hopefully our effect wouldn't disappear :D!).

If we can't swing more recruitment, is it defensible to freeze the sample and explicitly frame this as a pilot study?: “trust effect looks promising; performance is constrained by language/ASR issues; next study will (a) stratify or screen on language background, and (b) adjust the dialogue / ASR pipeline to be more robust.”

Either way, these results already give us a solid story: responsive Misty is perceived as more trustworthy, and the study has highlighted the need to take language and accent into account when designing HRI tasks that rely on spoken interaction.

Take a look at some of the effect plots I added below:


```{r}

library(lme4)
library(lmerTest)
library(ggeffects)
# mixed models

scores_df <- df_long_scores_final |>
  # filter(scale=='HRI_perception_post')|>
  mutate(nars_pre_c = scale(nars_pre, center = TRUE, scale = TRUE)) |>
  mutate(robot_trust_c = scale(robot_trust_pre, center = TRUE, scale = TRUE)) |>
  mutate(human_trust_c = scale(human_trust_pre, center = TRUE, scale = TRUE)) |>
  mutate(ai_trust_c = scale(ai_trust_pre, center = TRUE, scale = TRUE)) |>
  mutate(nfc_pre_c = scale(nfc_pre, center = TRUE, scale = TRUE)) |>
  mutate(
    nars_social_influence_robots_c = scale(
      nars_social_influence_robots,
      center = TRUE,
      scale = TRUE
    )
  ) |>
  mutate(
    nars_emotion_robots_c = scale(
      nars_emotion_robots,
      center = TRUE,
      scale = TRUE
    )
  ) |>
  mutate(
    nars_interaction_robots_c = scale(
      nars_interaction_robots,
      center = TRUE,
      scale = TRUE
    )
  ) |>
  mutate(trust_items = factor(trust_items)) |>
  mutate(robot_xp = relevel(robot_xp, ref = "No")) |>
  mutate(native_english = factor(native_english)) |>
  mutate(scale = factor(scale))

hist(scores_df$robot_trust_post)
hist(scores_df$robot_trust_post_c)

scores_df |>
  group_by(group, scale) |>
  summarise(
    n = n_distinct(session_id),
    mean_robot_trust = mean(robot_trust_post, na.rm = TRUE)
  )

```

Two participants did not complete pre-test measures and were excluded from analyses involving pre–post change but retained in post-test analyses. One participant omitted two post-test items; analyses used all available data without imputation.

```{r}

base = lm(robot_trust_post ~ group, data = scores_df)

mod1 <- lmer(
  robot_trust_post ~ group +
    (1 | session_id),
  data = scores_df
)

mod2 <- lmer(
  robot_trust_post ~ group +
    (1 | session_id) +
    (1 | trust_items),
  data = scores_df
)

mod3 <- lmer(
  robot_trust_post ~ group + trust_items + (1 | session_id),
  data = scores_df
)

mod4 <- lmer(
  robot_trust_post ~ group * trust_items + (1 | session_id),
  data = scores_df
)


# mod4 <- lmer(
#   robot_trust_post ~ group + scale +
#     (1 | session_id / robot_xp) +
#     (1 | trust_items),
#   data = scores_df
# )
anova(mod1, mod2, mod3, mod4, base)
tab_model(mod1, mod3, mod4)
#outliers_list <- check_outliers(mod3)
#lot(check_outliers(mod3))
compare_performance(mod1, mod2, mod3, mod4, rank = TRUE)

```

```{r}
mod_dep <- lmer(
  robot_trust_post ~ group +
    (1 | session_id) +
    (1 | trust_items),
  data = scores_df |> filter(scale != 'HRI_perception_post')
)
mod_dep2 <- lmer(
  robot_trust_post ~ group + nars_pre_c + (1 | session_id) + (1 | trust_items),
  data = scores_df |> filter(scale != 'HRI_perception_post')
)

# combine both scale in one model
mod_dep3 <- lmer(
  robot_trust_post ~ group + nars_pre_c + scale + (1 | session_id) + (1 | trust_items),
  data = scores_df )#> filter(scale == 'HRI_perception_post')


```



```{r}
library(brms)
# choose conservative priors (mean of 50 on 0-100 scale, wide SDs)
priors <- c(
  prior(normal(50, 25), class = "Intercept"), # trust score center-ish, wide
  prior(normal(0, 10), class = "b"), # effects in points on 0-100
  prior(exponential(1), class = "sd"), # RE SDs: subject/item
  prior(exponential(1), class = "sigma") # residual SD
)
# priors for the null
priors_null <- c(
  prior(normal(50, 25), class = "Intercept"),
  prior(exponential(1), class = "sd"),
  prior(exponential(1), class = "sigma")
)
# sensitivity analysis: wider and tighter priors
priors_wide <- c(
  prior(normal(50, 40), class = "Intercept"),
  prior(normal(0, 20), class = "b"),
  prior(exponential(0.5), class = "sd"),
  prior(exponential(0.5), class = "sigma")
)
priors_tight <- c(
  prior(normal(50, 20), class = "Intercept"),
  prior(normal(0, 7), class = "b"),
  prior(exponential(1.5), class = "sd"),
  prior(exponential(1.5), class = "sigma")
)
`
``
```{r}

dep1 <- brm(
  robot_trust_post ~ group +
    (1 | session_id) +
    (1 | trust_items),
  data = scores_df |> filter(scale == 'HRI_perception_post'),
  family = gaussian(),
  prior = priors,
  chains = 4,
  cores = 10,
  iter = 4000,
  warmup = 1000,
  control = list(adapt_delta = 0.95)
)

dep2 <- brm(
  robot_trust_post ~ group +
    (1 | session_id) +
    (1 | trust_items),
  data = scores_df |> filter(scale != 'HRI_perception_post'),
  family = gaussian(),
  prior = priors,
  chains = 4,
  cores = 10,
  iter = 4000,
  warmup = 1000,
  control = list(adapt_delta = 0.95)
)

```

```{r}
summary(dep1)
summary(dep2)

pp_check(dep1) # post_trust_perc
pp_check(dep2) # post_trust (likert)

nuts_params(dep1) %>% count(Parameter == "divergent__")
nuts_params(dep2) %>% count(Parameter == "divergent__")

post <- posterior::as_draws_df(dep1)

mean(post$b_groupRESPONSIVE > 0) # P(effect > 0)
mean(post$b_groupRESPONSIVE > 5) # P(effect > small)
mean(post$b_groupRESPONSIVE > 10) # P(effect > moderate)
mean(post$b_groupRESPONSIVE > 15) # P(effect > large)

post <- posterior::as_draws_df(dep2)

mean(post$b_groupRESPONSIVE > 0) # P(effect > 0)
mean(post$b_groupRESPONSIVE > 5) # P(effect > small)
mean(post$b_groupRESPONSIVE > 10) # P(effect > moderate)
mean(post$b_groupRESPONSIVE > 15) # P(effect > large)

VarCorr(dep1)
VarCorr(dep2)

```

```{r}

dep1_null <- brm(
  robot_trust_post ~ 1 + (1 | session_id) + (1 | trust_items),
  data = scores_df |> filter(scale == 'HRI_perception_post'),
  family = gaussian(),
  prior = priors_null,
  chains = 4,
  cores = 4,
  iter = 4000,
  warmup = 1000,
  control = list(adapt_delta = 0.95)
)

dep2_null <- brm(
  robot_trust_post ~ 1 + (1 | session_id) + (1 | trust_items),
  data = scores_df |> filter(scale != 'HRI_perception_post'),
  family = gaussian(),
  prior = priors_null,
  chains = 4,
  cores = 4,
  iter = 4000,
  warmup = 1000,
  control = list(adapt_delta = 0.95)
)

loo_compare(loo(dep1_null), loo(dep1))
loo_compare(loo(dep2_null), loo(dep2))

# Leave-one-out cross-validation indicated similar predictive performance for models with and without the group effect, suggesting that while the estimated effect was directionally positive, gains in out-of-sample prediction were modest in this pilot sample.

```



```{r}

dep1_wide <- update(
  dep1,
  prior = priors_wide,
  chains = 4,
  cores = 4,
  iter = 4000,
  warmup = 1000
)

dep2_wide <- update(
  dep2,
  prior = priors_wide,
  chains = 4,
  cores = 4,
  iter = 4000,
  warmup = 1000
)

posterior_summary(dep1, variable = "b_groupRESPONSIVE")
posterior_summary(dep2, variable = "b_groupRESPONSIVE")
posterior_summary(dep1_wide, variable = "b_groupRESPONSIVE")
posterior_summary(dep2_wide, variable = "b_groupRESPONSIVE")

```


Main Hypothesis Test: Does group (responsive vs control) predict higher robot trust ratings?

The Trust Perception Scale–HRI is a validated self-report measure specifically developed for human–robot interactions, and has most frequently been deployed in pre–post designs to quantify trust changes induced by interactions. In those contexts, differences of approximately 10 points on the 0–100 scale have been observed. Our study extends this literature by examining post-interaction trust differences between conditions; as expected, between-group differences estimated here were somewhat smaller (≈7–8 points) than typical pre–post effects, likely reflecting baseline variability not accounted for in post-only analyses. While self-report measures remain common, systematic reviews highlight that they are often combined with behavioural or physiological metrics to capture multifaceted aspects of trust.

Bayesian hierarchical models indicated higher post-interaction trust scores in the responsive robot condition across both trust-related scales (posterior mean differences ≈ 7–8 points on a 0–100 scale). Although 95% credible intervals overlapped zero, the posterior probability that the responsive condition increased trust was high for both measures (≈0.95), suggesting a robust directional effect alongside substantial individual variability.Sensitivity analyses using substantially wider priors yielded nearly identical posterior estimates for the group effect, indicating that results were not driven by prior specification.

In addition to directional effects, the posterior probability that the responsive condition increased trust by at least five points was approximately 0.70, suggesting a moderate likelihood of a practically meaningful effect despite substantial individual variability.

Descriptive comparisons of participant-level post-test scores indicated an approximately 10-point difference between conditions, although this did not reach conventional significance under a two-sample t-test, reflecting limited power (n = 29). Hierarchical Bayesian models that accounted for item-level structure yielded slightly smaller but consistent estimates (≈7–8 points) with high posterior probability of a positive effect. Notably, treating item-level responses as independent observations (i.e., ignoring nesting) substantially inflated apparent precision, underscoring that the observed uncertainty is primarily a function of sample size rather than absence of an effect. A larger sample would allow more precise estimation of the effect magnitude.

Although the two post-test trust instruments differed in original response format, both were linearly rescaled to a 0–100 metric for interpretability and comparability. Analyses were conducted separately for each scale, and posterior predictive checks indicated that Gaussian hierarchical models adequately captured the central tendency and variability of scores despite discretization. Negative attitudes toward robots (NARS) were negatively correlated with post-interaction trust, consistent with prior literature, and likely contributed to between-participant variability in post-only estimates.

Several behavioral and task-level measures were correlated with post-interaction trust, consistent with the interpretation that trust judgments were shaped by interaction quality; these variables were not included as covariates in primary models to avoid conditioning on potential mediators.

Baseline negative attitudes toward robots were most strongly associated with affective components of trust rather than perceptions of reliability, suggesting that pre-existing attitudes primarily shape emotional responses to interaction rather than judgments of system competence. Conversely, objective task performance was selectively associated with perceived reliability, indicating that participants distinguished between affective and functional aspects of trust.

Future work with larger samples could formally test mediation pathways linking robot responsiveness, interaction fluency, affective responses, and trust judgments, as well as moderation by baseline attitudes toward robots and need for cognition.

Participants in the responsive condition also exhibited higher levels of AI-detected engagement during interaction, as indexed by a greater number of responses classified as positive affect (t-test result). This suggests that responsive behaviors altered the affective tone of the interaction itself.

```{r}

```

```{r}
fixef(dep1)
fixef(dep2)

```

```{r}
posterior_summary(dep1, variable = "b_groupRESPONSIVE")
posterior_summary(dep2, variable = "b_groupRESPONSIVE")
```

```{r}
posterior <- as_draws_df(dep1)
mean(posterior$b_groupRESPONSIVE > 0)

posterior <- as_draws_df(dep2)
mean(posterior$b_groupRESPONSIVE > 0)
```

```{r}
post <- posterior::as_draws_df(dep1)

mean(post$b_groupRESPONSIVE > 0) # P(effect > 0)
mean(post$b_groupRESPONSIVE > 5) # P(effect > small)
mean(post$b_groupRESPONSIVE > 10) # P(effect > moderate)

```


```{r}

post <- posterior::as_draws_df(dep2)

mean(post$b_groupRESPONSIVE > 0) # P(effect > 0)
mean(post$b_groupRESPONSIVE > 5) # P(effect > small)
mean(post$b_groupRESPONSIVE > 10) # P(effect > moderate)


```



Pre-test measures (NARS overall and subscales; Need for Cognition) did not differ between groups at baseline (all ps > .33). Exploratory analyses including demographic variables (age, gender, major, English fluency, robot experience) also failed to improve model fit, suggesting that the observed group effect was not attributable to pre-existing differences between participants. Adding these variables as covariates to the mixed-effects model did not improve fit (ΔAIC = +3.9; χ²(2) = 0.06, p = .97). Therefore, the covariates were excluded from the final model.

Model comparisons using AIC, BIC, and AIC weights indicated that the model including treatment group, native English status, and prior robot experience provided the best fit among all tested models (AIC weight = .90). Adding native English significantly improved fit relative to the base model (ΔAIC = –4.8, χ²(1) = 6.72, p = .010), while including the group × native English interaction did not (p = .997). Prior robot experience did not individually predict trust but contributed marginally to overall variance reduction when included alongside native English. Thus, `robot_trust ~ group + native_english + robot_xp + (1 | session_id) + (1 | trust_items)` was selected as the final model.


To account for repeated trust ratings across items, we fit a mixed-effects model with random intercepts for participants and trust items. The model showed that participants in the responsive robot condition reported significantly higher trust than those in the control condition, b = 21.13, 95% CI [5.31, 36.95], p = .009. This represents an increase of approximately 21 percentage points in perceived robot trustworthiness.

The intraclass correlation coefficient (ICC = .62) indicated that most variance in trust ratings was attributable to differences between participants rather than items. The marginal R² (.174) suggests that the experimental condition explained 17% of the variance in trust, while the full model accounted for 69% (conditional R² = .688).

Adding pre-test measures (NARS subscales, Need for Cognition) as covariates did not improve model fit (ΔAIC = +3.9), and these variables did not differ between experimental groups, indicating that the trust effect is unlikely to be attributable to pre-existing attitudes or demographic differences.

We next evaluated whether participants' native English status influenced trust ratings. Though we hadn't anticipated needing to control for this (explain eligibility screening procedure an dhow we noted that regardless people signed up and the we manually documented these cases). Adding native English as a covariate significantly improved model fit (ΔAIC = –4.8; χ²(1) = 6.72, p = .009), indicating that non-native English speakers reported lower trust overall (b = –20.55, 95% CI [–36.04, –5.05]). However, adding a group × native English interaction did not improve fit (p = .997), suggesting that the effect of robot responsiveness on trust was consistent across language backgrounds.

Prior robot experience did not improve model fit (ΔAIC ≈ –1) and was therefore excluded from the final model.

```{r}
#| fig.height: 9
#| fig.width: 6

predictions <- predict_response(
  mod7,
  terms = c("group", "native_english", "robot_xp")
)

plot(predictions, n_rows = 1, connect_lines = TRUE, ci_style = 'dot') +
  theme(legend.position = "bottom") +
  scale_color_discrete() +
  theme(legend.position = "bottom", legend.direction = "vertical")

plot(predictions, n_rows = 1, connect_lines = TRUE, ci_style = 'dot') +
  theme(legend.position = "bottom") +
  scale_color_discrete() +
  ggtitle(
    "Treatment x Native English Speaker (True vs False)"
  ) +
  theme(legend.position = "bottom", legend.direction = "vertical")

```

```{r}

ggbetweenstats(x = group, y = trust_perc_post, df_flat_scores_final)

ggbetweenstats(x = group, y = post_trust, df_flat_scores_final)

```

'Several Generalized Linear Mixed Effects Models with random intercepts for participant and post-test trust items were fit with fixed effects for treatment group (responsive misty vs control), trust items, and their interaction, controlling for pre-test Negative Attitudes Towards Robots (NARS) and Need For Cognition (NFC) Scores. Even after controlling for language background (native English speaker) and prior experience with robots the treatment effect (responsive versus control) remained significant, predicting higher trust ratings after interacting with the responsive Misty compared to the control Misty (p < 0.002). The best fit is summarized in Table 3. (will add model tests here also, showing improvement of fit with addition of terms and interactions)'

```{r}

scores_df2 <- df_flat_scores_final |>
  select(
    session_id,
    email,
    group,
    gender,
    age,
    native_english,
    program,
    robot_xp,
    nars_pre,
    human_trust_pre,
    robot_trust_pre,
    ai_trust_pre,
    nars_social_influence_robots,
    nars_emotion_robots,
    nars_interaction_robots,
    nfc_pre,
    the_way_the_robot_moved_made_me_uncomfortable:the_robot_seemed_to_care_about_helping_me
  ) |>
  pivot_longer(
    the_way_the_robot_moved_made_me_uncomfortable:the_robot_seemed_to_care_about_helping_me,
    names_to = "trust_items",
    values_to = "robot_trust_post"
  ) |>
  # scale continuous predictors
  #mutate(robot_trust_c = scale(robot_trust, center=TRUE, scale=TRUE)) |>
  mutate(nars_pre_c = scale(nars_pre, center = TRUE, scale = TRUE)) |>
  mutate(nfc_pre_c = scale(nfc_pre, center = TRUE, scale = TRUE)) |>
  mutate(
    nars_social_influence_robots_c = scale(
      nars_social_influence_robots,
      center = TRUE,
      scale = TRUE
    )
  ) |>
  mutate(
    nars_emotion_robots_c = scale(
      nars_emotion_robots,
      center = TRUE,
      scale = TRUE
    )
  ) |>
  mutate(
    nars_interaction_robots_c = scale(
      nars_interaction_robots,
      center = TRUE,
      scale = TRUE
    )
  ) |>
  mutate(trust_items = factor(trust_items)) |>
  mutate(robot_xp = relevel(robot_xp, ref = "No")) |>
  mutate(native_english = factor(native_english))


```

```{r}
# put the other trust scale on the same 0-100 scale for easier interpretation
# scores_df2$robot_trust_post <- (scores_df2$robot_trust2 - 1) / 4 * 100

base <- lm(robot_trust_post ~ group, data = scores_df2)

mod1 <- lmer(
  robot_trust_post ~ group +
    (1 | session_id) +
    (1 | trust_items),
  data = scores_df2
)

mod2 <- lmer(
  robot_trust_post ~ group +
    nars_pre +
    nfc_pre +

    (1 | session_id) +
    (1 | trust_items),
  data = scores_df2
)

anova(mod1, mod2, base)

grouped_ggbetweenstats(
  x = group,
  y = robot_trust_post,
  grouping.var = trust_items,
  scores_df2
)

grouped_ggbetweenstats(
  x = group,
  y = robot_trust_post,
  grouping.var = trust_items,
  scores_df
)
```

Robot experience and native language predictors may overlap, as many of the participants with robot experience are international students.

```{r}

#| fig.height: 8
#| fig.width: 6
predictions <- predict_response(
  mod5,
  terms = c(
    "group",
    "trust_items",
    #"native_english",
    "robot_xp"
  )
)

plot(predictions, n_rows = 1, connect_lines = TRUE, ci_style = 'dot') +
  theme(legend.position = "bottom") +
  scale_color_discrete() +
  ggtitle(
    "Treatment x Prior Robot Experience (Yes vs No)"
  ) +
  theme(legend.position = "bottom", legend.direction = "vertical")

```

```{r}

```

```{r}
# put the likert scores on a 0-100 scale for easier interpretation

base <- lm(robot_trust ~ group + nars_pre + nfc_pre, data = scores_df2)

mod1 <- lmer(
  robot_trust ~ group +
    nars_pre +
    nfc_pre +
    (1 | session_id) +
    (1 | trust_items),
  data = scores_df2
)

mod2 <- lmer(
  robot_trust ~ group *
    #  trust_items +
    nars_pre +
    nfc_pre +
    (1 | session_id) +
    (1 | trust_items),
  data = scores_df2
)

mod3 <- lmer(
  robot_trust ~ group *
    trust_items +
    nars_pre +
    nars_pre_s1 +
    nars_pre_s2 +
    nars_pre_s3 +
    (1 | session_id),
  data = scores_df2
)

mod4 <- lmer(
  robot_trust ~ group *
    trust_items +
    native_english +
    nars_pre +
    nfc_pre +
    (1 | session_id),
  data = scores_df2
)


mod5 <- lmer(
  robot_trust ~ group *
    trust_items +
    robot_xp +
    native_english +
    nars_pre +
    nfc_pre +
    (1 | session_id),
  data = scores_df2
)

# predictions <- predict_response(mod2, terms = c("group", "trust_items"))

# plot(predictions, n_rows = 2) +
#   theme(legend.position = "bottom") +
#   scale_color_discrete()

#compare_performance(mod1, mod2, mod3, mod4, mod5, rank = TRUE)

# grouped_ggbetweenstats(
#   x = group,
#   y = robot_trust,
#   grouping.var = trust_items,
#   data = scores_df2
# )
grouped_ggbetweenstats(
  x = group,
  y = robot_trust2,
  grouping.var = trust_items,
  scores_df_2
)
```

The greatest predictor of success in completing tasks accurately was not group membership but whether someone was a native english speaker or not, suggesting that language comprehension and the quality of STT translations may have played a larger role in task performance than robot responsiveness. Future work should further explore how language background and robot dialogue systems interact to influence task performance. Solution to this problem could be improved ASR systems or simplified dialogue structures that are less reliant on complex language understanding.

```{r}

accuracy_df <- df2 |>
  select(
    session_id,
    group,
    gender,
    age,
    program,
    robot_xp,
    the_way_the_robot_moved_made_me_uncomfortable:the_robot_seemed_to_care_about_helping_me,
    native_english:n_frust
  ) |>
  pivot_longer(
    suspect_correct:zone_correct,
    names_to = "accuracy_items",
    values_to = "accuracy",
  ) |>
  left_join(
    df_flat_scores_final |>
      select(session_id, contains('nars_'), contains('nfc_')),
    by = "session_id"
  ) |>
  mutate(accuracy_items = factor(accuracy_items)) |>
  mutate(group = factor(group, levels = c("CONTROL", "EXPERIMENTAL"))) |>
  mutate(program = as_factor(program)) |>
  mutate(robot_xp = as_factor(robot_xp)) |>
  mutate(
    native_english = factor(native_english, levels = c("FALSE", "TRUE"))
  ) |>
  select(-total_correct)


base <- glm(
  accuracy ~ group + nars_pre + nfc_pre,
  family = binomial(link = "logit"),
  data = accuracy_df
)
base2 <- glm(
  accuracy ~ group + accuracy_items + nars_pre + nfc_pre,
  family = binomial(link = "logit"),
  data = accuracy_df
)
base3 <- glm(
  accuracy ~ group * accuracy_items + nars_pre + nfc_pre,
  family = binomial(link = "logit"),
  data = accuracy_df
)
base4 <- glm(
  accuracy ~ group * native_english + accuracy_items + nars_pre + nfc_pre,
  family = binomial(link = "logit"),
  data = accuracy_df
)

mod1 <- glmer(
  accuracy ~ group +
    nars_pre +
    nfc_pre +
    (1 | session_id) +
    (1 | accuracy_items),
  family = binomial(link = "logit"),
  data = accuracy_df
)


mod2 <- glmer(
  accuracy ~ group +
    accuracy_items +
    native_english +
    # robot_xp +
    nars_pre +
    nfc_pre +
    (1 | accuracy_items) +
    (1 | session_id),
  family = binomial(link = "logit"),
  data = accuracy_df
)
tab_model(mod2)

# predictions <- predict_response(mod2, terms = c("native_english", "group"))

# plot(predictions, n_rows = 2) +
#   theme(legend.position = "bottom") +
#   scale_color_discrete()

compare_performance(mod1, mod2, mod3, mod4, mod5, rank = TRUE)

# grouped_ggbetweenstats(x = group, y = accuracy, grouping.var = native_english, accuracy_df)
# mod3 <- lmer(
#   robot_trust ~ group *
#     trust_items +
#     nars_pre +
#     nars_pre_s1 +
#     nars_pre_s2 +
#     nars_pre_s3 +
#     (1 | session_id),
#   data = scores_df2
# )

# mod4 <- lmer(
#   robot_trust ~ group *
#     trust_items +
#     native_english +
#     nars_pre +
#     nfc_pre +
#     (1 | session_id),
#   data = scores_df2
# )

# mod5 <- lmer(
#   robot_trust ~ group *
#     trust_items +
#     robot_xp +
#     native_english +
#     nars_pre +
#     nfc_pre +
#     (1 | session_id),
#   data = scores_df2
# )
```

```{r}

# ggbetweenstats(x = group, y = nars_pre, df_flat_scores_final)
# ggbetweenstats(x = group, y = nars_pre_s1, df_flat_scores_final)
# ggbetweenstats(x = group, y = nars_pre_s2, df_flat_scores_final)
# ggbetweenstats(x = group, y = nars_pre_s3, df_flat_scores_final)

#ggbetweenstats(x = group, y = post_trust, df_flat_scores_final)

```